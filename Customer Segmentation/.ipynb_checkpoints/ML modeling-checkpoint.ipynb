{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pylab\n",
    "import matplotlib as mpl\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Going to use these 5 base models for the stacking\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "pd.set_option('max_columns', 1000) \n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')\n",
    "pylab.rcParams['figure.figsize'] = 12,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PROCESSED_DATA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scriptDir = os.getcwd()\n",
    "relPath = r\"../Customer Segmentation/\"\n",
    "sampleFilePath = os.path.join(scriptDir, relPath, 'whole_dataset.csv')\n",
    "relPathOutput = r\"../output/\"\n",
    "outputFolderPath = os.path.join(scriptDir, relPathOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(sampleFilePath, sep=',', header=0, quotechar='\"', encoding='latin1')\n",
    "df = df.drop(['companyid'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data For Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target = ['rebate(%)']\n",
    "Features = ['HashEncode_0', 'HashEncode_1', 'HashEncode_2', 'HashEncode_3',\n",
    "       'HashEncode_4', 'HashEncode_5', 'HashEncode_6', 'HashEncode_7',\n",
    "       'Round_trip', 'Scaled_gross_log', 'Scaled_Distance_log',\n",
    "       'Scaled_Total Flight Time (Dec)', 'Country_France', 'Country_Germany',\n",
    "       'Country_Italy', 'Country_Monaco', 'Country_Other', 'Country_Sweden',\n",
    "       'Country_Switzerland', 'Country_Turkey', 'Country_United Kingdom',\n",
    "       'Country_United States', 'Product_CJ - Adhoc', 'Product_Seat Sales',\n",
    "       'Product_Tour Ops', 'passengersRange_1', 'passengersRange_2',\n",
    "       'passengersRange_3', 'passengersRange_4', 'Class', 'categ_aircraft','categ_0', 'categ_1',  'categ_2',  'categ_3',  'categ_4','categ_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[Features], df[Target], test_size = 0.33, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling & Stacking models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## base-line classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(criterion='entropy')\n",
    "model.fit(X_train, y_train)\n",
    "y_test_hat = model.predict(X_test)   \n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_hat)\n",
    "print('Accuracy_score: %.2f%%' % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot_data = tree.export_graphviz(model, out_file=None, feature_names=Features, class_names=Target,\n",
    "#                                 filled=True, rounded=True, special_characters=True)\n",
    "# graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "# graph.write_pdf('airpartner.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction by using random forest\n",
    "- split the train dataset into trainset and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, train_y, val_y = train_test_split(X_train, y_train, train_size=0.8, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "\n",
    "rf_reg = RandomForestClassifier(n_estimators = 50, verbose=1)\n",
    "rf_reg.fit(train_data, train_y)\n",
    "\n",
    "combine_lists = lambda item: [item[0], item[1]]\n",
    "\n",
    "feature_imp = list(map(combine_lists, zip(train_data.columns, rf_reg.feature_importances_)))\n",
    "feature_imp = pd.DataFrame(\n",
    "        feature_imp, columns=['Feature', 'Importance']\n",
    ").sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All features with filtering importance less than 0.001 include constructed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_feature = feature_imp[feature_imp['Importance'] > 0.001]['Feature'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the basic prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 2\n",
    "classifiers = []\n",
    "\n",
    "classifiers.append(DecisionTreeClassifier(random_state=random_state))\n",
    "classifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\n",
    "classifiers.append(RandomForestClassifier(random_state=random_state))\n",
    "classifiers.append(ExtraTreesClassifier(random_state=random_state))\n",
    "classifiers.append(GradientBoostingClassifier(random_state=random_state))\n",
    "classifiers.append(SVC(random_state=random_state))\n",
    "classifiers.append(XGBClassifier())\n",
    "classifiers.append(MLPClassifier(random_state=random_state))\n",
    "classifiers.append(KNeighborsClassifier())\n",
    "classifiers.append(LogisticRegression(random_state = random_state))\n",
    "classifiers.append(LinearDiscriminantAnalysis())\n",
    "classifiers.append(BaggingClassifier())\n",
    "# classifiers.append(GaussianProcessClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = []\n",
    "for classifier in classifiers :\n",
    "    cv_results.append(cross_val_score(classifier, X_train, y = y_train, scoring = \"accuracy\", cv = kfold, n_jobs=4))\n",
    "    \n",
    "    \n",
    "cv_means = []\n",
    "cv_std = []\n",
    "for cv_result in cv_results:\n",
    "    cv_means.append(cv_result.mean())\n",
    "    cv_std.append(cv_result.std())\n",
    "\n",
    "cv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"DecisionTree\",\"AdaBoost\",\n",
    "\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"SVC\",\"XGboost\",\"MultipleLayerPerceptron\",\"KNeighboors\",\\\n",
    "\"LogisticRegression\",\"LinearDiscriminantAnalysis\",'Bagging']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(x = \"CrossValMeans\", y = \"Algorithm\", data = cv_res, color='m')\n",
    "plt.title('Machine Learning Algorithm Accuracy Score \\n')\n",
    "plt.xlabel('Accuracy Score (%)')\n",
    "plt.ylabel('Algorithm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tunning for best models\n",
    "- Bagging, AdaBoost, RandomForest and ExtraTrees perfrom the 70 plus score in the experiment, so that I choose those classifiers for the ensemble modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame({'Model': [],\n",
    "                           'Parameters':[],\n",
    "                           'Root Mean Squared Error (RMSE)':[],\n",
    "                           'R-squared (training)':[],\n",
    "                           'Adjusted R-squared (training)':[],\n",
    "                           'R-squared (test)':[],\n",
    "                           'Adjusted R-squared (test)':[],\n",
    "                           '10-Fold Cross Validation':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustedR2(r2,n,k):\n",
    "    return r2-(k-1)/(n-k)*(1-r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoostClassifier hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC = DecisionTreeClassifier()\n",
    "\n",
    "adaDTC = AdaBoostClassifier(DTC, random_state=7)\n",
    "\n",
    "ada_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "              \"base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "              \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n",
    "              \"n_estimators\" :[3,4],\n",
    "              \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.15, 0.2, 0.3,1.5]}\n",
    "\n",
    "gs_adaDTC = GridSearchCV(adaDTC,param_grid = ada_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gs_adaDTC.fit(train_data, train_y)\n",
    "\n",
    "ada_best = gs_adaDTC.best_estimator_\n",
    "pred = gs_adaDTC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_list(classifier):\n",
    "    rmsecm = float(format(np.sqrt(mean_squared_error(y_test,pred)),'.3f'))\n",
    "    rtrcm = float(format(classifier.score(X_train, y_train),'.3f'))\n",
    "    artrcm = float(format(adjustedR2(classifier.score(X_train, y_train),X_train.shape[0],len(Features)),'.3f'))\n",
    "    rtecm = float(format(classifier.score(X_test, y_test),'.3f'))\n",
    "    artecm = float(format(adjustedR2(classifier.score(X_test, y_test),X_test.shape[0],len(Features)),'.3f'))\n",
    "    return rmsecm, rtrcm, artrcm, rtecm,artecm\n",
    "\n",
    "rmsecm, rtrcm, artrcm, rtecm,artecm = score_list(gs_adaDTC)\n",
    "r = evaluation.shape[0]\n",
    "evaluation.loc[r] = ['AdaBoostClassifier',ada_best,rmsecm,rtrcm,artrcm,rtecm,artecm,gs_adaDTC.best_score_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExtraTree Classifier hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExtC = ExtraTreesClassifier()\n",
    "\n",
    "ex_param_grid = {\"max_depth\": [None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [False],\n",
    "              \"n_estimators\" :[100,300],\n",
    "              \"criterion\": [\"entropy\", \"gini\"]}\n",
    "\n",
    "\n",
    "gs_ExtC = GridSearchCV(ExtC,param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gs_ExtC.fit(train_data, train_y)\n",
    "\n",
    "ExtC_best = gs_ExtC.best_estimator_\n",
    "pred = gs_ExtC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsecm, rtrcm, artrcm, rtecm,artecm = score_list(ExtC_best)\n",
    "\n",
    "r = evaluation.shape[0]\n",
    "evaluation.loc[r] = ['ExtraTreesClassifier', ExtC_best, rmsecm, rtrcm, artrcm, rtecm, artecm, gs_ExtC.best_score_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest Classifier hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier()\n",
    "\n",
    "rf_param_grid = {\"max_depth\": [None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [False],\n",
    "              \"n_estimators\" :[100,300],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "\n",
    "\n",
    "gs_RFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gs_RFC.fit(X_train,y_train)\n",
    "\n",
    "RFC_best = gs_RFC.best_estimator_\n",
    "pred = gs_RFC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsecm, rtrcm, artrcm, rtecm,artecm = score_list(gs_RFC)\n",
    "\n",
    "r = evaluation.shape[0]\n",
    "evaluation.loc[r] = ['RandomForestClassifier', RFC_best, rmsecm, rtrcm, artrcm, rtecm, artecm, gs_RFC.best_score_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoosting Classifier hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC = GradientBoostingClassifier()\n",
    "gb_param_grid = {'loss' : [\"deviance\"],\n",
    "              'n_estimators' : [100,200,300],\n",
    "              'learning_rate': [0.1, 0.05, 0.01],\n",
    "              'max_depth': [4, 8],\n",
    "              'min_samples_leaf': [100,150],\n",
    "              'max_features': [0.3, 0.1] \n",
    "              }\n",
    "\n",
    "gs_GBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gs_GBC.fit(X_train,y_train)\n",
    "\n",
    "GBC_best = gs_GBC.best_estimator_\n",
    "pred = gs_GBC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsecm, rtrcm, artrcm, rtecm,artecm = score_list(gs_GBC)\n",
    "\n",
    "r = evaluation.shape[0]\n",
    "evaluation.loc[r] = ['GradientBoostingClassifier', GBC_best, rmsecm, rtrcm, artrcm, rtecm, artecm, gs_GBC.best_score_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BaggingClassifier hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BC = BaggingClassifier()\n",
    "\n",
    "bc_param_grid = {\"n_estimators\": [10, 30, 50, 100],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"max_samples\": [2, 3, 10],\n",
    "              \"bootstrap\": [\"False\", \"True\"],\n",
    "              \"warm_start\": [\"False\", \"True\"]}\n",
    "\n",
    "gs_BC = GridSearchCV(BC, param_grid = bc_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gs_BC.fit(X_train, y_train)\n",
    "\n",
    "BC_best = gs_BC.best_estimator_\n",
    "pred = gs_BC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsecm, rtrcm, artrcm, rtecm,artecm = score_list(gs_BC)\n",
    "\n",
    "r = evaluation.shape[0]\n",
    "evaluation.loc[r] = ['BaggingClassifier', GBC_best, rmsecm, rtrcm, artrcm, rtecm, artecm, gs_BC.best_score_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Learning curves\n",
    "- Learning curves are a good way to see the overfitting effect on the training set and the effect of the training size on the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"Generate a simple plot of the test and training learning curve\"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, \n",
    "                                        cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "g = plot_learning_curve(gs_RFC.best_estimator_,\"RF mearning curves\",X_train,y_train,cv=kfold)\n",
    "g = plot_learning_curve(gs_ExtC.best_estimator_,\"ExtraTrees learning curves\",X_train,y_train,cv=kfold)\n",
    "# g = plot_learning_curve(gs_SVMC.best_estimator_,\"SVC learning curves\",X_train,y_train,cv=kfold)\n",
    "g = plot_learning_curve(gs_adaDTC.best_estimator_,\"AdaBoost learning curves\",X_train,y_train,cv=kfold)\n",
    "g = plot_learning_curve(gs_GBC.best_estimator_,\"GradientBoosting learning curves\",X_train,y_train,cv=kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Confusion Matrix\n",
    "- plot the normalized and unnormalized confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix, recall_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print('Recall metric in the testing dataset: ', cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "class_names = ['rebate_0', 'rebate_1','rebate_2','rebate_3','rebate_4']\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, \n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph ML version of DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(DTC, out_file=None, \n",
    "                                feature_names = Features, class_names = True,\n",
    "                                filled = True, rounded = True)\n",
    "graph = graphviz.Source(dot_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance of tree based classifiers\n",
    "- In order to see the most informative features for the prediction of passengers survival, i displayed the feature importance for the 4 tree based classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = ncols = 2\n",
    "fig.tight_layout()\n",
    "fig, axes = plt.subplots(nrows = nrows, ncols = ncols, sharex=\"all\", figsize=(15,15))\n",
    "plt.subplots_adjust(wspace =0.45, hspace =0.1)\n",
    "\n",
    "names_classifiers = [(\"AdaBoosting\", ada_best),(\"ExtraTrees\",ExtC_best),(\"RandomForest\",RFC_best),(\"GradientBoosting\",GBC_best)]\n",
    "\n",
    "nclassifier = 0\n",
    "for row in range(nrows):\n",
    "    for col in range(ncols):\n",
    "\n",
    "        name = names_classifiers[nclassifier][0]\n",
    "        classifier = names_classifiers[nclassifier][1]\n",
    "        indices = np.argsort(classifier.feature_importances_)[::-1][:40]\n",
    "        g = sns.barplot(y=X_train.columns[indices][:40],x = classifier.feature_importances_[indices][:40] , orient='h',ax=axes[row][col])\n",
    "        g.set_xlabel(\"Relative importance\",fontsize=12)\n",
    "        g.set_title(name + \" feature importance\")\n",
    "        nclassifier += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Survived_RFC = pd.Series(RFC_best.predict(X_test), name=\"RFC\")\n",
    "test_Survived_ExtC = pd.Series(ExtC_best.predict(X_test), name=\"ExtC\")\n",
    "test_Survived_DTC = pd.Series(DTC_best.predict(X_test), name=\"DTC\")\n",
    "test_Survived_AdaC = pd.Series(ada_best.predict(X_test), name=\"Ada\")\n",
    "test_Survived_GBC = pd.Series(GBC_best.predict(X_test), name=\"GBC\")\n",
    "\n",
    "# Concatenate all classifier results\n",
    "ensemble_results = pd.concat([test_Survived_RFC,test_Survived_ExtC,test_Survived_AdaC,test_Survived_GBC, test_Survived_DTC],axis=1)\n",
    "\n",
    "g= sns.heatmap(ensemble_results.corr(),annot=True,linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble modeing\n",
    "- I choose a voting classifier to combine the predicitions coming from the 5 classifiers.\n",
    "- I preferred to pass the argument 'soft' to the voting parameter to take into account the probability of each vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votingC = VotingClassifier(estimators=[('rfc', RFC_best), ('extc', ExtC_best),\\\n",
    "('dtc', DTC_best), ('adac',ada_best),('gbc',GBC_best)], voting='soft', n_jobs=4)\n",
    "\n",
    "votingC = votingC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Prediction and Submit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rebate = pd.Series(votingC.predict(X_test), name=\"rebate(%)\")\n",
    "\n",
    "results = pd.concat([y_test, test_rebate],axis=1)\n",
    "\n",
    "results.to_csv(\"ensemble_python_voting.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
